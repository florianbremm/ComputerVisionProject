{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db2a870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/group.kurse/cviwo012/ComputerVisionProject\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/group.kurse/cviwo012/my-env/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ComputerVisionProject/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df41d3b8",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0905d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from CellDataset import CellDataset\n",
    "from MoCoResNetBackbone import MoCoResNetBackbone\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap.umap_ as umap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import AgglomerativeClustering, HDBSCAN\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    adjusted_rand_score,\n",
    "    normalized_mutual_info_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8899e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_unsupervised(X, labels_pred):\n",
    "    if len(set(labels_pred)) > 1:\n",
    "        sil = silhouette_score(X, labels_pred)\n",
    "        db = davies_bouldin_score(X, labels_pred)\n",
    "    else:\n",
    "        sil, db = np.nan, np.nan\n",
    "    return sil, db\n",
    "\n",
    "def evaluate_supervised(y_true, y_pred):\n",
    "    ari = adjusted_rand_score(y_true, y_pred)\n",
    "    nmi = normalized_mutual_info_score(y_true, y_pred)\n",
    "    return ari, nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33144ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_reduce_embeddings(checkpoint_path, val_list, device, label_mode='dead_alive', num_frames_labels=10, batch_size=64, reducers=None):\n",
    "    # 1. Load model\n",
    "    model = MoCoResNetBackbone()\n",
    "    model.to(device)\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "\n",
    "    # 2. Load dataset and DataLoader\n",
    "    dataset = CellDataset(video_list=val_list, mode='inference', label_mode=label_mode, num_frames_labels=num_frames_labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "    # 3. Extract embeddings and labels\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(dataloader, desc=\"Extracting embeddings\"):\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            embeddings = model.encode_query(imgs).cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            all_embeddings.append(embeddings)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # 4. Run dimensionality reduction\n",
    "    reduced_results = {}\n",
    "    if reducers is not None:\n",
    "        for name, reducer in reducers.items():\n",
    "            print(f\"Running {name}...\")\n",
    "            reduced = reducer.fit_transform(embeddings)\n",
    "            reduced_results[name] = reduced\n",
    "\n",
    "    return reduced_results, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c418ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_projections(reduced_results, cluster_labels, method_name=\"Unknown\", save_dir=None):\n",
    "    for reducer_name, X_2d in reduced_results.items():\n",
    "        plt.figure(figsize=(7, 6))\n",
    "        plt.scatter(X_2d[:, 0], X_2d[:, 1], c=cluster_labels, s=5, alpha=0.6)\n",
    "        plt.title(f\"{method_name} clustering shown via {reducer_name}\")\n",
    "        plt.xlabel(\"Component 1\")\n",
    "        plt.ylabel(\"Component 2\")\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_dir:\n",
    "            plt.savefig(Path(save_dir) / f\"{method_name}_{reducer_name}_clusters.png\", dpi=300)\n",
    "        else:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30f974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clustering_evaluation(label_mode, num_frames, cluster_configs, device, model_path, val_list, reduced_results=None, batch_size=64):\n",
    "    print(f\"\\n=== Running for label_mode='{label_mode}' | num_frames={num_frames} ===\")\n",
    "    \n",
    "    # 1. Load model\n",
    "    model = MoCoResNetBackbone()\n",
    "    model.to(device)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "\n",
    "    # 2. Init dataset and labels\n",
    "    dataset = CellDataset(video_list=val_list[:10], mode='inference', label_mode=label_mode, num_frames_labels=num_frames)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "    # 3. Extract embeddings\n",
    "    all_embeddings, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(dataloader, desc=f\"Extracting embeddings for '{label_mode}'\"):\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            embeddings = model.encode_query(imgs).cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            all_embeddings.append(embeddings)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # 4. Apply PCA\n",
    "    pca = PCA(n_components=10)\n",
    "    X_pca = pca.fit_transform(embeddings)\n",
    "\n",
    "    # 5. Run clustering with different settings\n",
    "    results = []\n",
    "    for method_name, clusterer_factory in cluster_configs.items():\n",
    "        print()\n",
    "        model = clusterer_factory()\n",
    "        labels_pred = model.fit_predict(X_pca)\n",
    "\n",
    "        if reduced_results:\n",
    "            plot_cluster_projections(reduced_results, labels_pred, method_name=method_name, save_dir=\"plots\")\n",
    "\n",
    "        sil, db = evaluate_unsupervised(X_pca, labels_pred)\n",
    "        ari, nmi = evaluate_supervised(labels, labels_pred)\n",
    "        n_clusters = len(set(labels_pred)) - (1 if -1 in labels_pred else 0)\n",
    "\n",
    "        results.append({\n",
    "            \"LabelMode\": label_mode,\n",
    "            \"Method\": method_name,\n",
    "            \"#Clusters\": n_clusters,\n",
    "            \"Silhouette\": sil,\n",
    "            \"DBIndex\": db,\n",
    "            \"ARI\": ari,\n",
    "            \"NMI\": nmi\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd945090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Configuration ==========\n",
    "checkpoint_path = Path(\"/scratch/cv-course-group-5/models/training4/model_epoch50.pth\")  # adjust if needed\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "\n",
    "_json_path = Path('train_test_split.json')\n",
    "\n",
    "# Load the file\n",
    "with open(_json_path, 'r') as f:\n",
    "    _split_data = json.load(f)\n",
    "\n",
    "# Access the train and test entries\n",
    "train_list = _split_data.get(\"train\", [])\n",
    "test_list = _split_data.get(\"test\", [])\n",
    "val_list = _split_data.get(\"val\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2284f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction methods\n",
    "reducers = {\n",
    "    \"PCA\": PCA(n_components=2),\n",
    "    \"t-SNE\": TSNE(n_components=2, perplexity=30, random_state=42),\n",
    "    \"UMAP\": umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6d27d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define configs (you can expand this later)\n",
    "cluster_2 = {\n",
    "    \"HDBSCAN\": lambda: HDBSCAN(min_cluster_size=100),\n",
    "    \"GMM-2\": lambda: GaussianMixture(n_components=2, covariance_type='full', random_state=42),\n",
    "    #\"GMM\": GaussianMixture(n_components=2, covariance_type='full', random_state=42, weights_init=[0.96, 0.04]),\n",
    "    \"Agglomerative-2\": lambda: AgglomerativeClustering(n_clusters=2, linkage='complete'),\n",
    "}\n",
    "\n",
    "cluster_3 = {\n",
    "    \"HDBSCAN\": lambda: HDBSCAN(min_cluster_size=100),\n",
    "    \"GMM-3\": lambda: GaussianMixture(n_components=3, covariance_type='full', random_state=42),\n",
    "    \"Agglomerative-3\": lambda: AgglomerativeClustering(n_clusters=3, linkage='complete'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1b3b95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 836/836 [00:36<00:00, 22.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCA...\n",
      "Running t-SNE...\n",
      "Running UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/group.kurse/cviwo012/my-env/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/group.kurse/cviwo012/my-env/lib/python3.9/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "reduced_results, labels = extract_and_reduce_embeddings(\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    val_list=val_list[:10],\n",
    "    device=device,\n",
    "    label_mode='dead_alive',\n",
    "    num_frames_labels=10,\n",
    "    batch_size=64,\n",
    "    reducers=reducers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658b8c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running for label_mode='dead_alive' | num_frames=10 ===\n",
      "53453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings for 'dead_alive': 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 836/836 [00:36<00:00, 23.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run for both label modes\n",
    "results_all = []\n",
    "\n",
    "r = run_clustering_evaluation(\n",
    "    label_mode='dead_alive',\n",
    "    num_frames=10,\n",
    "    cluster_configs=cluster_2,\n",
    "    device=device,\n",
    "    model_path=checkpoint_path,\n",
    "    val_list=val_list[:10],\n",
    "    reduced_results=reduced_results,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "results_all.extend(r)\n",
    "\n",
    "r = run_clustering_evaluation(\n",
    "    label_mode='dead_alive_dividing',\n",
    "    num_frames=10,\n",
    "    cluster_configs=cluster_3,\n",
    "    device=device,\n",
    "    model_path=checkpoint_path,\n",
    "    val_list=val_list[:10],\n",
    "    reduced_results=reduced_results,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "results_all.extend(r)\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "results_df = pd.DataFrame(results_all)\n",
    "results_df.to_csv(\"clustering_eval_results.csv\", index=False)\n",
    "\n",
    "# Optional: print\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7dae59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
