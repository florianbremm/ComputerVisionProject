{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms as T\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n"
   ],
   "id": "f0e68a9dcdac66b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ------------  CONFIG  -------------------\n",
    "base_path = '/scratch/cv-course-group-5/data/dataset_jpg'\n",
    "src_root   = Path(base_path + '/dataset')\n",
    "anno_file  = Path(base_path + '/dataset/annotations.json')"
   ],
   "id": "d4fd3d210ee05a5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load annotations\n",
    "annos_dict = json.loads(anno_file.read_text())\n",
    "\n",
    "annos = annos_dict.get('annotations', [])\n",
    "videos = annos_dict.get('videos', [])\n",
    "images = annos_dict.get('images', [])\n",
    "\n",
    "video_id2name = {v[\"id\"]: v[\"name\"] for v in videos}\n",
    "image_by_id = {img[\"id\"]: img for img in images}"
   ],
   "id": "57bbdc5fe596e7c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "filtered_annos = [ann for ann in annos if ann['bbox'][2] > 400 or ann['bbox'][3] > 400]\n",
    "\n",
    "# Step 1: Create a lookup from image_id to file_name\n",
    "image_id_to_filename = {img[\"id\"]: img[\"file_name\"] for img in images}\n",
    "\n",
    "# Step 2: Map filtered annotations to their filenames\n",
    "for i in range(len(filtered_annos)):\n",
    "    image_id = filtered_annos[i]['image_id']\n",
    "    filename = image_id_to_filename.get(image_id, \"UNKNOWN\")\n",
    "    filtered_annos[i]['filename'] = filename"
   ],
   "id": "4dad0e7d4e58fa46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# How many full images to show\n",
    "N = 20\n",
    "\n",
    "for i, ann in enumerate(filtered_annos[:N]):\n",
    "    file_path = os.path.join(src_root, ann[\"filename\"])\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Missing file: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    # Load full image\n",
    "    img = Image.open(file_path).convert(\"RGB\")\n",
    "\n",
    "    # Show full image\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Frame {ann['time_step']} | Filename {ann['filename']}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ],
   "id": "c3e0f96208bbed5b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
